\chapter{Conclusion}\label{ch:conclusion}
\setlength{\epigraphwidth}{0.90\textwidth}
\epigraph{``We are all shaped by the tools we use, in particular: the formalisms we use shape our thinking habits, for better or for worse, and that means that we have to be very careful in the choice of what we learn and teach, for unlearning is not really possible.''}{\begin{flushright}--Edsger W. \citet{dijkstra2000answers}, \href{https://www.cs.utexas.edu/~EWD/transcriptions/EWD13xx/EWD1305.html}{\textit{Answers to questions from students of Software Engineering}}\end{flushright}}

In this work, we explored four different programming tools from software engineering for the development of intelligent systems, broadly addressing cognitive complexity arising in various stages of Royce's Waterfall method~\autoref{fig:waterfall_model}. These tools have varying degrees of practicality, from highly experimental (adversarial testing of differentiable programs ~\autoref{ch:difftest}) to more pragmatic (containerization ~\autoref{ch:ducker}). In each, we provide some motivating examples and use cases which demonstrate key deficiencies in the current state of programming tools for intelligent systems and propose candidate solutions which address a few of those shortcomings. While we certainly hope that intelligent system programmers (e.g. roboticists and machine learning practitioners) may derive some value from the tools themselves, our intention is to be \textit{instructive} rather than \textit{prescriptive}.

By building tools and validating their effectiveness for toy applications, we hope that middleware and tools developers will carefully consider the cognitive complexity which software abstraction can introduce and the importance of notational and denotational design practices. In addition, we hope that by providing some examples illustrating programming tools in the ML/IS domain, developers will be inspired to re-imagine the possibilities for computer-aided programming towards the design of intelligent systems and begin to design better tools for developers working on similar problems.

By complementing the cognitive abilities of human programmers -- who excel at creative problem solving and high-level abstract reasoning -- with the low-level symbolic processing capabilities of programming tools, we can accelerate the design, development and validation of intelligent systems in real-world applications. This process, we argue, deserves more specific tools than general-purpose programming due to the opportunities and challenges which intelligent systems present and the unique interplay of human-machine intelligence.

As we start to engineer autonomous systems which take increasingly human decisions, programmers will play a critical role in shaping the behavior and dynamics of these systems. In order to build trustworthy autonomous systems, it will be important to have tools which enable humans to understand and inform their behavior in a more rigorous manner than monitoring training curves and performing hyperparameter sweeps. This requires us to actively rethink the programming model in machine learning to incorporate human knowledge, e.g. using differentiable programming and type theory (\autoref{ch:kotlingrad}) or building custom tools which incorporate automatic reasoning capabilities and visualization tools (e.g. customized run and debugging assistance \autoref{ch:hatchery}). Finally, to make the resulting software artifacts more reproducible will require sound build systems and best practices for reproducible software installation and configuration (\autoref{ch:ducker}).

\section{Future work}

\subsection{Requirements engineering}

Traditional software engineering has followed a rigorous process model and testing methodology. This model has guided the development of traditional software engineering, intelligent systems will need to re-imagine these ideas to build systems which adapt to their environment. Intelligent systems are trained on objective functions, which are typically one- or low-dimensional metrics for evaluating the performance of the system. Most often, these take the form of a single or small set of criteria, such as an \textit{error} or \textit{loss} which can represent descriptive phenomena such as latency, safety, energy efficiency or any number of objective measures.

In traditional software engineering, it is reasonable to assume the people who are implementing a system have some implicit knowledge and are generally well-intentioned human beings working towards a common goal. When building an intelligent system, it is not unreasonable to assume is that the entity implementing our requirements is a na\"ive but powerful genie. When given an optimization metric, it will take every available shortcut to satisfy that criteria. If we are not careful about engineering the requirements correctly, this entity can produce a system that does not work, or has unintended consequences.

When building an intelligent system developers must first ask, ``What are the requirements of the system?'' This question is often the most troublesome part, because the requirements must not be fuzzy specifications as often the case in software engineering, but precise constraints on the space of solutions. In a strict sense, specifying the requirements is often indistinguishable from implementing the system. With the right language abstractions (e.g.\ declarative programming), requirements and implementation can take the same notation. These ideas have been explored in recent decades with declarative languages like SQL and Prolog.

For example, in the design of a web-based advertisement recommendation system, we can optimize for various objectives such as click rate, engagement, sales conversion. So long as we can measure these parameters, modern function approximators can optimize for any single criterion or combination thereof. Much of the work involved in machine learning is finding representations which are suitable for downstream tasks, and prevent unintended consequences. For example, by optimizing for click rate, we create an artificial market for click bots. Similarly, in self-driving vehicles, we often want to optimize for passenger safety. However, by doing so na\"ively, we create a vehicle that never moves, or always yields to nearby vehicles.
