\documentclass{beamer}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage{amsmath}



\lstdefinelanguage{Kotlin}{
comment=[l]{//},
commentstyle={\color{gray}\ttfamily},
emph={delegate, filter, first, firstOrNull, forEach, lazy, map, mapNotNull, println, return@},
emphstyle={\color{red}},
identifierstyle=\color{black},
keywords={abstract, actual, as, as?, break, by, class, companion, continue, data, do, dynamic, else, enum, expect, false, final, for, fun, get, if, import, in, infix, interface, internal, is, null, object, open, operator, override, package, private, public, return, sealed, set, super, suspend, this, throw, true, try, typealias, val, var, vararg, when, where, while},
keywordstyle={\color{blue}\bfseries},
morecomment=[s]{/*}{*/},
morestring=[b]",
morestring=[s]{"""*}{*"""},
ndkeywords={@Deprecated, @JvmField, @JvmName, @JvmOverloads, @JvmStatic, @JvmSynthetic, Array, Byte, Double, Float, Int, Integer, Iterable, Long, Number, Runnable, Short, String},
ndkeywordstyle={\color{Orange}\bfseries},
sensitive=true,
stringstyle={\color{green}\ttfamily},
showstringspaces=false,
}

% Comparison Table
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{float}
\newcommand{\wmark}{\textcolor{orange}{\ding{45}}}
\newcommand{\cmark}{\textcolor{green!80!black}{\ding{51}}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\mediumwell}[1]{\textcolor{green}{#1}}
\newcommand{\medium}[1]{\textcolor{yellow}{#1}}
\newcommand{\mediumrare}[1]{\textcolor{orange}{#1}}
\newcommand{\rare}[1]{\textcolor{red}{#1}}

\mode<presentation> { \usetheme{Madrid} }

\title{Kotlin\texorpdfstring{$\nabla$}{}}
\subtitle{A Shape Safe eDSL for Differentiable Functional Programming}
\author{Breandan Considine}
\institute[UdeM]{
Universit\'e de Montr\'eal \\
\medskip
\textit{breandan.considine@umontreal.ca}
}
\date{\today}

\begin{document}
    \begin{frame}
        \titlepage
    \end{frame}

    \begin{frame}
        \frametitle{Overview}
        \tableofcontents
    \end{frame}

    \section{A Short Lesson on Computing Derivatives}\label{sec:second-section}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Differentiation}
        If we have a function, $P(x): \mathbb{R}\rightarrow\mathbb{R}$, recall the derivative is defined as:
        %
        \begin{equation}
            P'(x) = \lim _{h\to 0}{\frac {f(x+h)-f(x)}{h}} = \frac{\Delta y}{\Delta x} = \frac{dP}{dx}
        \end{equation}
        %
        For $P(x_0, x_1, \dots, x_n): \mathbb{R}^n\rightarrow\mathbb{R}$, the gradient is a vector of derivatives:
        %
        \begin{equation}
            \nabla P = \left[\frac{\partial P}{\partial x_0}, \frac{\partial P}{\partial x_1}, \dots, \dfrac{\partial P}{\partial x_n}\right]\text{ where }\frac{\partial P}{\partial x_i} = \frac{dP}{dx_i}
        \end{equation}
        %
        For $\mathbf{P}(x_0, x_1, \dots, x_n): \mathbb{R}^n\rightarrow\mathbb{R}^m$, the Jacobian is a vector of gradients:
        %
        \begin{equation}
            \mathbf{J}_\mathbf{P} = \left[\nabla P_0, \nabla P_1, \dots, \nabla P_n \right] \text{ or equivalently, } \mathbf{J}_{ij} = \frac{\partial P_i}{\partial x_j}
        \end{equation}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \section{Introduction and motivation}\label{sec:first-section}

    \begin{frame}
        \frametitle{Type checking automatic differentiation}
        Suppose we have a program $P: \mathbb{R}\rightarrow\mathbb{R}$ where:
        %
        \begin{equation}
            \mathbf{P}(p_0)=p_q \circ p_{q-1} \circ p_{q-2} \circ \dots \circ p_1 \circ p_0
        \end{equation}
        %
        From the chain rule of calculus, we know that:
        %
        \begin{equation}
            \frac{dP}{dp_0} = \frac{dp_q}{dp_{q-1}}\frac{dp_{q-1}}{dp_{q-2}}\dots\frac{dp_1}{dp_0}= {\displaystyle \prod_{i=1}^{n} \frac{dp_{i}}{dp_{i-1}}}
        \end{equation}
        %
        More generally, for $P: \mathbb{R}^n\rightarrow\mathbb{R}^m$, the chain rule also applies:
        %
        \begin{equation}
            \mathbf{J}_\mathbf{P} = \displaystyle \prod_{i=1}^{q} \mathbf{J}_{p_i} = \bigg(\Big((\mathbf{J}_{p_q} \mathbf{J}_{p_{q-1}}) \dots \mathbf{J}_{p_2}\Big) \mathbf{J}_{p_1}\bigg) = \bigg(\mathbf{J}_{p_q} \Big(\mathbf{J}_{p_{n-1}} \dots (\mathbf{J}_{p_2} \mathbf{J}_{p_1})\Big)\bigg)
        \end{equation}
        %
        In order for $\mathbf{P}$ to type check, what is the type signature of $p_{0<i<n}$?
        %
        \begin{equation}
            p_i: T_{out}(p_{i-1}) \rightarrow T_{in}(p_{i+1})
        \end{equation}
        %
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Shape checking and inference}
        \begin{itemize}
            \item Scalar functions implicitly represent shape as arity $f(1, 2): \mathbb{R}^2 \rightarrow \mathbb{R}$
            \item To check matrix functions, we need a type-level encoding of shape
            \item Arbitrary matrix functions (e.g.\ convolution) require dependent types
            \item But parametric polymorphism will suffice for most matrix functions
            \item For arithmetical operations, we just need to check for equality
        \end{itemize}
        {\scriptsize
\begin{table}
    \begin{tabular}{|c|c|c|c|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Math}}  & \textbf{Derivative}           & \textbf{Code}                                                                                  &  \textbf{Type Signature}                                                                                                                                                                                    \\ \hline
                 $a(b)$             & $\mathbf{J}_a\mathbf{J}_b$             & \texttt{a(b)}                                                                                  &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{\pi}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{\tau})   \rightarrow (\mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{\pi})$                \\ \hline
                 $a + b$            & $\mathbf{J}_a + \mathbf{J}_b$          & \begin{tabular}{@{}c@{}}\texttt{a + b}\\\texttt{a.plus(b)}\\\texttt{plus(a, b)}\end{tabular}   &  $ (\texttt{a}:  \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{\pi}, \texttt{b}: \mathbb{R}^{\lambda} \rightarrow \mathbb{R}^{\pi}) \rightarrow (\mathbb{R}^{?}\rightarrow \mathbb{R}^{\pi})$                     \\ \hline
                 $a   b$            & $\mathbf{J}_a b + \mathbf{J}_b a$      & \begin{tabular}{@{}c@{}}\texttt{a * b}\\\texttt{a.times(b)}\\\texttt{times(a, b)}\end{tabular} &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}^{m \times n}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}^{n \times p})    \rightarrow (\mathbb{R}^{?}\rightarrow\mathbb{R}^{m \times p})$ \\ \hline
                 $a ^ b$            & \tiny{$a^b(a'\frac{b}{a} + b'\ln a)$}  & \begin{tabular}{@{}c@{}}\texttt{a.pow(b)}\\\texttt{pow(a, b)}\end{tabular}                     &  $ (\texttt{a}: \mathbb{R}^{\tau}\rightarrow\mathbb{R}, \texttt{b}: \mathbb{R}^{\lambda}\rightarrow\mathbb{R}) \rightarrow (\mathbb{R}^{?}\rightarrow\mathbb{R}) $                                          \\ \hline
    \end{tabular}
\end{table}
}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Numeric tower}
        \begin{itemize}
            \item Abstract algebra can be useful when generalizing to new structures
            \item Helps us to easily translate between mathematics and source code
            \item Fields are a useful concept when computing over real numbers
            \begin{itemize}
                \item A field is a set $\mathbb{F}$ with two operations $+$ and $\times$, with the properties:
                \begin{itemize}
                    \item Associativity: $\forall a, b, c \in \mathbb{F}, a + (b + c) = (a + b) + c$
                    \item Commutivity: $\forall a, b \in \mathbb{F}, a + b = b + a$ and $a\times b = b\times a$
                    \item Distributivity: $\forall a, b, c \in \mathbb{F}, a \times (b \times c) = (a \times b) \times c$
                    \item Identity: $\forall a \in \mathbb{F}, \exists 0$, $ 1 \in F$ s.t. $a + 0 = a$ and $a\times 1= a$
                    \item $+$ inverse: $\forall a\in \mathbb{F}, \exists (-a)$ s.t. $a + (-a) = 0$
                    \item $\times$ inverse: $\forall a\neq 0 \in \mathbb{F}, \exists (a^{-1})$ s.t. $a \times a^{-1} = 1$
                \end{itemize}
            \end{itemize}
            \item Extensible to other number systems (e.g. complex, dual numbers)
            \item What is a program, but a series of arithmetic operations?
        \end{itemize}
    \end{frame}

    %------------------------------------------------------------------------------------------------

    \begin{frame}
        \frametitle{Why Kotlin?}
        \begin{itemize}
            \item Goal: To implement automatic differentiation in Kotlin
            \item Kotlin is a language with strong static typing and null safety
            \item Supports first-class functions, higher order functions and lambdas
            \item Has support for algebraic data types, via tuples & sealed classes
            \item Extension functions, operator overloading & other syntax sugar
            \item Offers features for embedding domain specific languages (DSLs)
            \item Access to all libraries and frameworks in the JVM ecosystem
            \item Multi-platform and cross-platform (JVM, Android, iOS, JS, native)
        \end{itemize}
        \begin{center}
            \includegraphics[scale=0.05]{kotlin.png}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Kotlin\texorpdfstring{$\nabla$}{} Priorities}
        \begin{itemize}
            \item Type system
            \begin{itemize}
                \item Strong type system based on algebraic principles
                \item Leverage the compiler for static analysis
                \item No implicit broadcasting or shape coercion
                \item Parameterized numerical types and arbitary-precision
            \end{itemize}
            \item Design principles
            \begin{itemize}
                \item Functional programming and lazy numerical evaluation
                \item Eager algebraic simplification of expression trees
                \item Operator overloading and tapeless reverse mode AD
            \end{itemize}
            \item Usage desiderata
            \begin{itemize}
                \item Generalized AD with functional array programming
                \item Automatic differentiation with infix and Polish notation
                \item Partials and higher order derivatives and gradients
            \end{itemize}
            \item Testing and validation
            \begin{itemize}
                \item Numerical gradient checking and property-based testing
                \item Performance benchmarks and thorough regression testing
            \end{itemize}
        \end{itemize}
    \end{frame}

\begin{frame}
    \frametitle{Feature Comparison Matrix}
    \begin{center}
\begin{tabular}{lllllllll}
    \textbf{Framework} &
    \textbf{Language} &
    SD &
    AD &
    FP &
    TS &
    SS &
    DP &
    MP
    \\ \hline
Kotlin$\nabla$     & Kotlin  & \cmark & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark \\
DiffSharp          & F\#     & \xmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark \\
TensorFlow.FSharp  & F\#     & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
Myia               & Python  & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
Deeplearning.scala & Scala   & \xmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark \\
Nexus              & Scala   & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
Lantern            & Scala   & \xmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark \\
Grenade            & Haskell & \xmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark \\
Eclipse DL4J       & Java    & \xmark & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark \\
Halide             & C++     & \xmark & \cmark & \xmark & \cmark & \xmark & \cmark & \xmark \\
Stalin$\naba$      & Scheme  & \xmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark \\
\end{tabular}
\end{center}
\footnotesize{SD: Symbolic Differentiation, AD: Automatic Differentiation, FP: Functional Program, TS: Type Safe, SS: Shape Safe, DP: Differentiable Programming, MP: Multiplatform}
%    \begin{itemize}
%       \item
%    \end{itemize}
\end{frame}

    \begin{frame}[fragile]
        \frametitle{How do we define algebraic types in Kotlin\texorpdfstring{$\nabla$}{}?}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            // T: Group<T> is effectively a self type
            interface Group<T: Group<T>> {
                operator fun plus(f: T): T
                operator fun unaryMinus(): X
                operator fun minus(f: X): X = this + -f
                operator fun times(f: T): T
            }

            interface Field<X: Group<X>> {
              val e: X
              val one: X
              val zero: X
              operator fun div(f: X): X = this * f.pow(-one)
              infix fun pow(f: X): X
              fun ln(): X
            }
        \end{lstlisting}
    \end{frame}


    \section{Architectural Overview}\label{sec:third-section}

    \begin{frame}[fragile]
        \frametitle{Algebraic Data Types}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            class Var<X: Fun<X>>(label: String): Fun<X>()
            class Const<X: Fun<X>>(val num: Number): Fun<X>()
            class Sum<X: Fun<X>>(val f1: X, val f2: X): Fun<X>()
            class Prod<X: Fun<X>>(val f1: X, val f2: X): Fun<X>()

            sealed class Fun<X: Fun<X>>: Field<Fun<X>>{
              open fun diff(): Fun<X> = when(this) {
                is Const -> Zero
                is Sum -> f1.diff() + f2.diff()
                is Prod -> f1.diff() * f2 + f1 * f2.diff()
                is Var -> One
              }

              operator fun plus(f: Fun<X>) = Sum(this, f)
              operator fun times(f: Fun<X>) = Prod(this, f)
            }
        \end{lstlisting}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Expression simplification}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            operator fun times(exp: Fun<X>): Fun<X> = when {
              this is Const && num == 0.0 -> Const(0.0)
              this is Const && num == 1.0 -> exp
              exp is Const && exp.num == 0.0 -> exp
              exp is Const && exp.num == 1.0 -> this
              this is Const && exp is Const -> Const(num*exp.num)
              else -> Prod(this, e)
            }

            // Sum(Prod(Const(2.0), Var()), Const(6.0))
            val q = Const(2.0) * Sum(Var(), Const(3.0))
        \end{lstlisting}
    \end{frame}


    \begin{frame}[fragile]
        \frametitle{Extension functions and contexts}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            object DoublePrecision {
              operator fun Number.times(f: Fun<KGDouble>) =
                Const(toDouble()) * f
            }

            class KGDouble(num: Double): Const<KGDouble>(num) {
              override val e by lazy { KGDouble(Math.E) }
              override val one by lazy { KGDouble(1.0) }
              override val zero by lazy { KGDouble(0.0) }
              // Adapters for wrapping primitive Double...
            }

            // Uses `*` operator in DoubleContext
            fun Fun<KGDouble>.multiplyByTwo() =
              with(DoublePrecision) { 2 * this }
        \end{lstlisting}
    \end{frame}

    \begin{frame}[fragile]
        \frametitle{Automatic test case generation}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            val x = Var("x")
            val y = Var("y")

            val z = y * (sin(x * y) - x) // Function under test
            val dz_dx = d(z) / d(x)      // Automatic derivative
            val manualDx = y * (cos(x * y) * y - 1)

            "dz/dx should be y * (cos(x * y) * y - 1)" {
              assertAll (DoubleGenerator) { cx, cy ->
                // Evaluate the results at a given seed
                val autoEval = dz_dx(x to cx, y to cy)
                val symbEval = manualDx(x to cx, y to cy)
                // Should pass if |adEval - manualEval| < eps
                autoEval shouldBeApproximately symbEval
              }
            }
        \end{lstlisting}
    \end{frame}

    \section{Usage}\label{sec:fourth-section}

    \begin{frame}[fragile]
        \frametitle{Usage: plotting higher derivatives of nested functions}
        \begin{lstlisting}[language=Kotlin, gobble=12]
            with(DoublePrecision) {// Use double-precision
             val x = variable()  // Declare an immutable variable
             val y = sin(sin(sin(x)))/x + sin(x) * x + cos(x) + x

             // Lazily compute reverse-mode automatic derivatives
             val dy_dx = d(y) / d(x)
             val d2y_dx = d(dy_dx) / d(x)
             val d3y_dx = d(d2y_dx2) / d(x)
             val d4y_dx = d(d3y_dx3) / d(x)
             val d5y_dx = d(d4y_dx4) / d(x)

             plot(-10..10, dy_dx, dy2_dx, d3y_dx, d4y_dx, d5y_dx)
            }
        \end{lstlisting}
    \end{frame}

    \begin{frame}
        \frametitle{$y = \frac{\sin{\sin{\sin{x}}}}{x} + x \sin{x} + \cos{x} + x$, $\frac{dy}{dx}$, $\frac{d^{2}y}{dx^2}$, $\frac{d^{3}y}{dx^3}$, $\frac{d^{4}y}{dx^4}$, $\frac{d^{5}y}{dx^5}$}
        \begin{center}
            \includegraphics[scale=0.4]{plot.png}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{$z = \sin(10(x^2 + y^2)) / 10$, $\frac{\partial^3 z}{\partial^2 y \partial x}$}
        \begin{center}
            \includegraphics[scale=0.4]{plot3d.png}
        \end{center}
    \end{frame}

    \section{Future exploration}\label{sec:fifth-section}

    \begin{frame}
        \frametitle{Further directions to explore}
        \begin{itemize}
            \item Theory Directions
            \begin{itemize}
                \item Generalization of types to higher order functions, vector spaces
                \item Dependent types via code generation to type-check convolution
                \item General programming operators and data structures
                \item Imperative define-by-run array programming syntax
                \item Program induction and synthesis, cf.
                \begin{itemize}
                    \item The Derivative of a Regular Type is its Type of One-Hole Contexts
                    \item The Differential Lambda Calculus (2003)
                \end{itemize}
                \item Asynchronous gradient descent (cf. HogWild, YellowFin, et al.)
            \end{itemize}
            \item Implementation Details
            \begin{itemize}
                \item Closer integration with Kotlin/Java standard library
                \item Encode additional structure, i.e. function arity into type system
                \item Vectorized optimizations for matrices with certain properties
                \item Configurable forward and backward AD modes based on dimension
                \item Automatic expression refactoring for numerical stability
                \item \href{https://discuss.kotlinlang.org/t/primitive-type-specialization/11022}{Primitive type specialization}, i.e. \texttt{FloatVector <: Vector<T>}?
            \end{itemize}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \begin{center}
            \Huge{Learn more at: \\~\\
            \url{http://kg.ndan.co}}
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Special thanks}
        \begin{itemize}
            \begin{center}
                \huge{
                Liam Paull \\
                Michalis Famelis \\
                }
                \includegraphics[scale=0.4]{cser_logo.png}\\
                \includegraphics[scale=0.1]{udem.png}
                \includegraphics[scale=0.4]{mila.png}
            \end{center}
        \end{itemize}
    \end{frame}
\end{document}

    %------------------------------------------------------------------------------------------------

    %    \begin{frame}
    %        \frametitle{Symbolic differentiation}
    %        \begin{itemize}
    %            \item What about evaluating functions symbolically?
    %            \item Computer algebra systems for manipulate symbolic formulas
    %        \end{itemize}
    %    \end{frame}

    %------------------------------------------------------------------------------------------------

    %    \begin{frame}
    %        \frametitle{Automatic differentiation}
    %        \begin{itemize}
    %            \item Derivatives can be calculated automatically? (Wengert, 1964)
    %            \item Code as an \textit{exact} symbolic representation of functions
    %            \item To reason about code we need the ability to treat \textit{code as data}:
    %            \begin{itemize}
    %                \item Reflection and metaprogramming
    %                \item Domain specific languages
    %                \item First-class functions
    %            \end{itemize}
    %        \end{itemize}
    %    \end{frame}

    %------------------------------------------------------------------------------------------------

    %    \begin{frame}
    %        \frametitle{Differentiable [functional] programming}
    %        \begin{itemize}
    %            \item What is a program, but a series of arithmetic operations?
    %            \item What are arithmetic operations but syntactic sugar for functions?
    %            \item Functions can be composed of other functions or chained in sequence
    %            \item High school calculus gives us rules for differentiating function chains
    %            \item Pearlmutter \& Siskind teach us AD is possible just using FP (2016)
    %            \item Wang, Rompf, et al. show us this is possible \textit{without a tape}! (2018)
    %        \end{itemize}
    %    \end{frame}

    %------------------------------------------------------------------------------------------------

    %    \begin{frame}
    %        \frametitle{Differentiable programming with algebraic types}
    %        \begin{itemize}
    %            \item Combine the tools from mathematics and CS
    %            \item Type safety
    %            \item Static analysis
    %            \item Allows us to preserve symmetries that are not obvious
    %            \item There is an abstract algebra for tensor manipulations
    %            \item Can be encoded using OOP and parametric polymorphism
    %            \item \href{https://arxiv.org/pdf/1610.07690.pdf}{Operational Calculus for Differentiable Programming}
    %        \end{itemize}
    %    \end{frame}

    %------------------------------------------------------------------------------------------------

